{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rToK0Tku8PPn"
      },
      "source": [
        "## makemore: becoming a backprop ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sFElPqq8PPp"
      },
      "outputs": [],
      "source": [
        "# there no change change in the first several cells from last lecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChBbac4y8PPq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the names.txt file from github\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "id": "x6GhEWW18aCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510a7585-2571-4e6b-83f5-f8dd48676acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-05 13:24:54--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "\rnames.txt             0%[                    ]       0  --.-KB/s               \rnames.txt           100%[===================>] 222.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-07-05 13:24:54 (10.0 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klmu3ZG08PPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87435628-49c4-4faa-e9a5-05c2cc6a8735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32033\n",
            "15\n",
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
          ]
        }
      ],
      "source": [
        "# read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "print(len(words))\n",
        "print(max(len(w) for w in words))\n",
        "print(words[:8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCQomLE_8PPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5757fca4-f301-4b3a-9f43-08cddb9991ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_zt2QHr8PPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5f1fa7-5424-42c5-842f-aece88476012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ],
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg20-vsg8PPt"
      },
      "outputs": [],
      "source": [
        "# ok biolerplate done, now we get to the action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJPU8HT08PPu"
      },
      "outputs": [],
      "source": [
        "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlFLjQyT8PPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a044ea87-a5a5-4e1f-98f4-844a44dae3e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4137\n"
          ]
        }
      ],
      "source": [
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden))*0.1\n",
        "\n",
        "# Note: I am initializating many of these parameters in non-standard ways\n",
        "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
        "# implementation of the backward pass.\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY-y96Y48PPv"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "n = batch_size # a shorter variable also, for convenience\n",
        "# construct a minibatch\n",
        "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ofj1s6d8PPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14f2e7b-3539-485f-92b9-04b917267166"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3159, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
        "\n",
        "emb = C[Xb] # embed the characters into vectors\n",
        "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "# Linear layer 1\n",
        "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "# BatchNorm layer\n",
        "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff**2\n",
        "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n), useful for deriving a better estimate of a populations variance from a small sample (which Minibatches are). Using 1/n tends to underestimate the variance\n",
        "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "# Non-linearity\n",
        "h = torch.tanh(hpreact) # hidden layer\n",
        "# Linear layer 2\n",
        "logits = h @ W2 + b2 # output layer\n",
        "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
        "logit_maxes = logits.max(1, keepdim=True).values\n",
        "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# PyTorch backward pass\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
        "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "loss.backward()\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO-8aqxK8PPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c886602-9c80-4086-fdc4-506339af2bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "hpreact         | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
            "bngain          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnraw           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
            "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnvar           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
            "bndiff2         | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
            "bndiff          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
            "bnmeani         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "hprebn          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "embcat          | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
            "W1              | exact: False | approximate: True  | maxdiff: 6.51925802230835e-09\n",
            "b1              | exact: False | approximate: True  | maxdiff: 3.259629011154175e-09\n",
            "emb             | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
            "C               | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
          ]
        }
      ],
      "source": [
        "# Exercise 1: backprop through the whole thing manually,\n",
        "# backpropagating through exactly all of the variables\n",
        "# as they are defined in the forward pass above, one by one\n",
        "\n",
        "# -----------------\n",
        "# YOUR CODE HERE :)\n",
        "# -----------------\n",
        "\n",
        "\n",
        "#Tip 1: Gradient Dimensions must be the same as Data Dimensions\n",
        "\n",
        "dlogprobs = torch.zeros(n,vocab_size) #Intuit. the logprobs not \"plucked\" out will have gradient of 0, as changing the values at the level of logprobs has no effect on the loss\n",
        "dlogprobs[range(n), Yb] += -1.0/n\n",
        "cmp('logprobs', dlogprobs, logprobs)\n",
        "\n",
        "dprobs = (1.0/probs)*dlogprobs\n",
        "cmp('probs', dprobs, probs)\n",
        "\n",
        "# counts_sum_inv.shape is 32, 1 and counts shape is 32,27, thus counts_sum_inv is broadcasted/replicated; thus counts would be local derivative of dprobs/counts_sum_inv when counts_sum_inv is replicated. To account for broadcasting in this instance, we know counts_sum_inv (which has 32 elements), has each of these 32 elements basically used 27x times when multiplied by counts and as we know if a variable/node is used multiple times in a function, their total gradient is the sum of indiv. gradient\n",
        "\n",
        "# dcounts_sum_inv = torch.unsqueeze(counts[range(n), Yb]*dprobs[range(n), Yb], dim = -1); I knew this from hand-deriving gradients, but below is a viable solution too\n",
        "\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims = True)\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "\n",
        "dcounts_sum = (-1*counts_sum**-2)*dcounts_sum_inv\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)\n",
        "\n",
        "# probs = counts * counts_sum_inv (where counts_sum_inv is in its broadcasted form)\n",
        "# counts_sum[0] = counts[0][0] + counts[0][1] + ... + counts[0][27], derivative of counts_sum[0] w.r.t to any of these elements is 1\n",
        "dcounts = counts_sum_inv*dprobs + torch.ones(counts.shape)*dcounts_sum\n",
        "cmp('counts', dcounts, counts)\n",
        "\n",
        "dnorm_logits = norm_logits.exp()*dcounts\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)\n",
        "\n",
        "# logits.shape is 32, 27 and logit_maxes is 32, 1, so each elements of logit_maxes are used 27x times in logits - logit_maxes (broadcasting once again), so sum the individual gradients for each element to compute the final value\n",
        "dlogit_maxes = -1.0 * dnorm_logits.sum(1, keepdims = True)\n",
        "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
        "\n",
        "# Remember we are only using logit_maxes for numerical stability, and if you remember, if you add or subtract values equally to all components of a tensor, the associated output probabilites will remain the same\n",
        "# Thus, if logit_maxes does not change the probs, and therefore does not change the loss, then the gradient on logits_maxes should be 0. Because of floating point error, the values in the computer will be close but not equal to 0\n",
        "# If we did want to compute dlogit_maxes/dlogits, we need to take dl/logit_maxes and scatter it to the correct position of the logits (i.e max values)\n",
        "\n",
        "dlogits = 1*dnorm_logits\n",
        "dlogit_maxes_dlogits = torch.zeros(logits.shape)\n",
        "dlogit_maxes_dlogits[range(n), logits.max(1).indices] = 1\n",
        "dlogits += dlogit_maxes_dlogits*dlogit_maxes\n",
        "\n",
        "#Could also one one-hot instead of torch.zero\n",
        "\n",
        "cmp('logits', dlogits, logits)\n",
        "\n",
        "dh = dlogits @ W2.T #h = (32, 64), W2 = (64, 27), dlogits = (32, 27), b = (27) but is broadcasted to (32, 27), dlogits @ W2 = 32 64; use shapes to resolve\n",
        "cmp('h', dh, h)\n",
        "\n",
        "dW2 = h.T @ dlogits\n",
        "cmp('W2', dW2, W2)\n",
        "\n",
        "db2 = dlogits.sum(dim = 0, keepdims = True)\n",
        "cmp('b2', db2, b2)\n",
        "\n",
        "dhpreact = (1.0 - (torch.tanh(hpreact)**2)) * dh\n",
        "cmp('hpreact', dhpreact, hpreact)\n",
        "\n",
        "#bngain is (1,64), bnbias is 1,64, and  bnraw is (32, 64), so bngain * bnraw uses a broadcasted/repeated version of bngain, where each of the 64 elements is 32x, and thus we sum the individual 32 gradients for eeach of the 64 elements to compute the total gradient for each element\n",
        "dbngain = (bnraw * dhpreact).sum(0, keepdim = True)\n",
        "cmp('bngain', dbngain, bngain)\n",
        "\n",
        "#Similiar to above, as bnbias is broadcasted\n",
        "dbnbias = dhpreact.sum(0, keepdim = True)\n",
        "cmp('bnbias', dbnbias, bnbias)\n",
        "\n",
        "#we are using broadcasted version of bngain, as in the forward pass it is replicated the same way\n",
        "dbnraw = bngain * dhpreact\n",
        "cmp('bnraw', dbnraw, bnraw)\n",
        "\n",
        "#bnvar_inv shape is (1,64), bndiff shape is (32, 64), and bnraw shape is (32, 64)\n",
        "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim = True)\n",
        "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
        "\n",
        "#bnvar shape is 1,64\n",
        "dbnvar = -0.5*((bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "cmp('bnvar', dbnvar, bnvar)\n",
        "\n",
        "#bndiff2 shape is 32,64, since forward pass added the elements column wise, as we know the backward pass of addition simply routes the gradients to the compontents of the forward sum, in this case elements from the same column get the same gradient\n",
        "#Tip 2: Forward pass has sum, backward pass must have some broadcasting or replication in same dim\n",
        "#Tip 3: Forward pass has broadcasting, backward pass must have sum in same dim\n",
        "\n",
        "dbndiff2 = 1/(n-1)*torch.ones(bndiff2.shape)*dbnvar\n",
        "cmp('bndiff2', dbndiff2, bndiff2)\n",
        "\n",
        "dbndiff = 2*bndiff*dbndiff2 + dbnraw * bnvar_inv\n",
        "cmp('bndiff', dbndiff, bndiff)\n",
        "\n",
        "#bndiff shape is (32, 64), hprebn shape is (32, 64), bnmeani shape (1, 64)\n",
        "dbnmeani = -1*dbndiff.sum(0, keepdim = True)\n",
        "cmp('bnmeani', dbnmeani, bnmeani)\n",
        "\n",
        "dhprebn = dbndiff + torch.ones(hprebn.shape)* 1/n * dbnmeani\n",
        "cmp('hprebn', dhprebn, hprebn)\n",
        "\n",
        "dembcat = dhprebn @ W1.T\n",
        "cmp('embcat', dembcat, embcat)\n",
        "\n",
        "dW1 = embcat.T @ dhprebn\n",
        "cmp('W1', dW1, W1)\n",
        "\n",
        "db1 = dhprebn.sum(0, keepdims = True)\n",
        "cmp('b1', db1, b1)\n",
        "\n",
        "demb = dembcat.view(emb.shape)\n",
        "cmp('emb', demb, emb) #Derivative of view operation is view operation to original shape\n",
        "\n",
        "#emb.shape is 32,3,10     C.shape is 27, 10,     Xb shape is 32,3\n",
        "#We need to find which row of C, did each of these 10D embeddings come from, and deposit them into dC. If an embedding was used more then once, need to remember, indiv. gradients sum\n",
        "\n",
        "dC = torch.zeros(C.shape)\n",
        "for i, idx in enumerate(Xb):\n",
        "  for j in range(len(idx)):\n",
        "    dC[idx[j]] += demb[i].view(3, -1)[j]\n",
        "\n",
        "cmp('C', dC, C)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tip 1: Gradient Dimensions must be the same as Data Dimensions\n",
        "\n",
        "Tip 2: When needing to compress/reduce dimensions during gradient computation, summing is a good attmept"
      ],
      "metadata": {
        "id": "_0ol5fDJykAE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebLtYji_8PPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c1db5b-509c-4b9d-8794-5db574aeaa12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3158581256866455 diff: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2: backprop through cross_entropy but all in one go\n",
        "# to complete this challenge look at the mathematical expression of the loss,\n",
        "# take the derivative, simplify the expression, and just write it out\n",
        "\n",
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# logit_maxes = logits.max(1, keepdim=True).values\n",
        "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# now:\n",
        "loss_fast = F.cross_entropy(logits, Yb)\n",
        "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gCXbB4C8PPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246a07b0-4bd6-49a4-cf1d-ece0577f2491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 27])\n",
            "torch.Size([32, 27])\n",
            "logits          | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
          ]
        }
      ],
      "source": [
        "# backward pass\n",
        "#Doing this generates both a faster forward pass and backward pass\n",
        "# -----------------\n",
        "# YOUR CODE HERE :)\n",
        "# TODO. my solution is 3 lines\n",
        "print(logits.shape)\n",
        "\n",
        "dlogits = (1/n)*F.softmax(logits, 1)\n",
        "dlogits[range(n), Yb] += (-1/n)*1\n",
        "\n",
        "print(dlogits.shape)\n",
        "# -----------------\n",
        "\n",
        "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd-MkhB68PPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de24a880-499c-45b2-e04a-6b291606f418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# Exercise 3: backprop through batchnorm but all in one go\n",
        "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
        "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
        "# BatchNorm paper: https://arxiv.org/abs/1502.03167\n",
        "\n",
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "# bndiff = hprebn - bnmeani\n",
        "# bndiff2 = bndiff**2\n",
        "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "# bnraw = bndiff * bnvar_inv\n",
        "# hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# now:\n",
        "\n",
        "#NEEDED HELP, TRY AGAIN\n",
        "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
        "print('max diff:', (hpreact_fast - hpreact).abs().max())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hidy9eW0E_ne",
        "outputId": "3f1babbc-d6bd-42cc-b7aa-0335c9b0170b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0020,  0.0030,  0.0006,  0.0016,  0.0006,  0.0026,  0.0007,  0.0011,\n",
              "        -0.0307,  0.0010,  0.0012,  0.0011,  0.0012,  0.0009,  0.0011,  0.0004,\n",
              "         0.0003,  0.0006,  0.0005,  0.0016,  0.0015,  0.0007,  0.0008,  0.0022,\n",
              "         0.0019,  0.0009,  0.0007], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0CGbWOZFKaN",
        "outputId": "0f9756b6-46cc-4cdc-b4b2-adf642fb3c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.3283e-09, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will find that dlogits for a particular example will sum to 0, where incorrect classes have positive grad, which will reduce their values, and the correct class will have a negative grad, which will increase it value\n",
        "\n",
        "The amount of \"force\" we are applying to update these logits, it proportional to the probs which came out in the forward pass. Where if our probs came out exactly correct, 1.0 at correct class and 0 elsewhere, the dlogits would be all a row of 0 for that example, no push and pull. However, if you have a confidently mispredicted example, that element will be pulled down very heavily, and the correct answer will be pulled up the same amount"
      ],
      "metadata": {
        "id": "RLx97cNDFN6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "plt.imshow(dlogits.detach(), cmap = \"gray\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "fwTSqGwwFDPw",
        "outputId": "4a5db9e7-4e58-4882-8eae-c4aea52d9632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78d7207d5660>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4qGJfGJiE7Fj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POdeZSKT8PPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb48fd95-484d-4869-df26-25e73efeff55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 64])\n",
            "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ],
      "source": [
        "# backward pass\n",
        "\n",
        "# before we had:\n",
        "# dbnraw = bngain * dhpreact\n",
        "# dbndiff = bnvar_inv * dbnraw\n",
        "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
        "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
        "# dbndiff += (2*bndiff) * dbndiff2\n",
        "# dhprebn = dbndiff.clone()\n",
        "# dbnmeani = (-dbndiff).sum(0)\n",
        "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "\n",
        "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
        "# (you'll also need to use some of the variables from the forward pass up above)\n",
        "\n",
        "#ignore gamma and beta\n",
        "\n",
        "# -----------------\n",
        "# YOUR CODE HERE :)\n",
        "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "print(hprebn.shape)\n",
        "# -----------------\n",
        "\n",
        "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPy8DhqB8PPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78aee285-e95c-4bf4-dc5c-2bae6e488bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12297\n",
            "      0/ 200000: 3.7863\n",
            "100\n"
          ]
        }
      ],
      "source": [
        " # Exercise 4: putting it all together!\n",
        "# Train the MLP neural net with your own backward pass\n",
        "\n",
        "# init\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden))*0.1\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True\n",
        "\n",
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "n = batch_size # convenience\n",
        "lossi = []\n",
        "\n",
        "# use this context manager for efficiency once your backward pass is written (TODO)\n",
        "#with torch.no_grad():\n",
        "\n",
        "# kick off optimization\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xb] # embed the characters into vectors\n",
        "  embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "  # Linear layer\n",
        "  hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "  # BatchNorm layer\n",
        "  # -------------------------------------------------------------\n",
        "  bnmean = hprebn.mean(0, keepdim=True)\n",
        "  bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
        "  bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "  bnraw = (hprebn - bnmean) * bnvar_inv\n",
        "  hpreact = bngain * bnraw + bnbias\n",
        "  # -------------------------------------------------------------\n",
        "  # Non-linearity\n",
        "  h = torch.tanh(hpreact) # hidden layer\n",
        "  logits = h @ W2 + b2 # output layer\n",
        "  loss = F.cross_entropy(logits, Yb) # loss function\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward() # use this for correctness comparisons, delete it later!\n",
        "\n",
        "  # manual backprop! #swole_doge_meme\n",
        "  # -----------------\n",
        "  # YOUR CODE HERE :)\n",
        "\n",
        "  dlogits = (1/n)*F.softmax(logits, 1)\n",
        "  dlogits[range(n), Yb] += (-1/n)*1\n",
        "\n",
        "  dh = dlogits @ W2.T\n",
        "  dW2 = h.T @ dlogits\n",
        "  db2 = dlogits.sum(dim = 0, keepdims = True)\n",
        "  dhpreact = (1.0 - (torch.tanh(hpreact)**2)) * dh\n",
        "\n",
        "  dbngain = (bnraw * dhpreact).sum(0, keepdim = True)\n",
        "  dbnbias = dhpreact.sum(0, keepdim = True)\n",
        "  dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "\n",
        "  dembcat = dhprebn @ W1.T\n",
        "  dW1 = embcat.T @ dhprebn\n",
        "  db1 = dhprebn.sum(0, keepdims = True)\n",
        "  demb = dembcat.view(emb.shape)\n",
        "\n",
        "  dC = torch.zeros(C.shape)\n",
        "  for k, idx in enumerate(Xb):\n",
        "    for j in range(len(idx)):\n",
        "      dC[idx[j]] += demb[k].view(3, -1)[j]\n",
        "\n",
        "  grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
        "  # -----------------\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
        "  for p, grad in zip(parameters, grads):\n",
        "    p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
        "    #p.data += -lr * grad # new way of swole doge TODO: enable\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        "\n",
        "  if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
        "    print(i)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEpI0hMW8PPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1660d9-0058-4980-a490-e104d1bf3016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27, 10)        | exact: False | approximate: True  | maxdiff: 1.1175870895385742e-08\n",
            "(30, 200)       | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
            "(200,)          | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
            "(200, 27)       | exact: False | approximate: True  | maxdiff: 2.2351741790771484e-08\n",
            "(27,)           | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
            "(1, 200)        | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n",
            "(1, 200)        | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
          ]
        }
      ],
      "source": [
        "# useful for checking your gradients\n",
        "for p,g in zip(parameters, grads):\n",
        "  cmp(str(tuple(p.shape)), g, p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KImLWNoh8PP0"
      },
      "outputs": [],
      "source": [
        "# calibrate the batch norm at the end of training\n",
        "\n",
        "with torch.no_grad():\n",
        "  # pass the training set through\n",
        "  emb = C[Xtr]\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  # measure the mean/std over the entire training set\n",
        "  bnmean = hpreact.mean(0, keepdim=True)\n",
        "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aFnP_Zc8PP0"
      },
      "outputs": [],
      "source": [
        "# evaluate train and val loss\n",
        "\n",
        "@torch.no_grad() # this decorator disables gradient tracking\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "  logits = h @ W2 + b2 # (N, vocab_size)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esWqmhyj8PP1"
      },
      "outputs": [],
      "source": [
        "# I achieved:\n",
        "# train 2.0718822479248047\n",
        "# val 2.1162495613098145"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHeQNv3s8PP1"
      },
      "outputs": [],
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # forward pass\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "      hpreact = embcat @ W1 + b1\n",
        "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "      logits = h @ W2 + b2 # (N, vocab_size)\n",
        "      # sample\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}